# 데이터 조인

## 데이터 조인 

+ **RDBMS와 유사한 조인 연산자**

    스파크의 조인 연산자는 pairRDD에만 활용할 수 있다. (너무나도 당연하다. 조인하기 위해서는 서로 매칭되는 key값이 있어야 하기 때문에)

#### 1) **join** 
 RDBMS의 내부조인과 동일하다. key값을 기준으로 두개의 RDD가 가지고 있는 모든 요소를 포함한 PairRDD를 리턴한다.



> PairRDD1( K, V).join(PairRDD2(K,W)) 
>  => PairRDD3 (K, (V,W))


        scala> val totalsAndProds = totalsByProd.join(products)
        totalsAndProds: org.apache.spark.rdd.RDD[(Int, (Double, Array[String]))] = MapPartitionsRDD[54] at join at <console>:34

        scala> totalsAndProds.first
        res40: (Int, (Double, Array[String])) = (84,(75192.53,Array(84, Cyanocobalamin, 2044.61, 8)))


어느 한쪽에만 있는 key의 경우 결과에서 제외된다. 

#### 2) **leftOuterjoin** 
 (K, (V,W))대신에 (K,(V, Option(W))) 타입의 RDD를 반환한다. 첫번째에만 있는 Key의 Value는 결과 RDD에 (K, (V,none))으로 저장되며, 두번째 RDD에만 있는 Key는 결과에서 제외된다. 


        scala> val totalWithMissingProds = products.leftOuterJoin(totalsByProd)
        totalWithMissingProds: org.apache.spark.rdd.RDD[(Int, (Array[String], Option[Double]))] = MapPartitionsRDD[57] at leftOuterJoin at <console>:34

#### 3) rightOuterJoin

leftOuterJoin과 정 반대의 결과를 반환한다. 


    scala> val totalWithMissingProd = products.rightOuterJoin(totalsByProd)
    totalWithMissingProd: org.apache.spark.rdd.RDD[(Int, (Option[Array[String]], Double))] = MapPartitionsRDD[64] at rightOuterJoin at <console>:34

#### 4) fullOuterJoin

left와 right에서 반환하는 모든 결과의 합집합이다. 

***


조인할 두 RDD의 요소중 키가 중복된 요소는 여러번 조인한다. _즉, 동일한 key값에 대해서 RDD1에 3개가, RDD2에 2개가 존재한다면, 결과RDD에는 해당 키값을 가진 데이터는 총 6개가됨을 의미한다_

두 RDD를 조인할 때, partitioner의 객체나 파티션 개수를 지정해 줄 수 있다. 만약 지정을 하지 않는다면, 파티션의 개수는 첫번째 RDD의 partitioner를 사용한다. 만약 두 RDD모두 partitioner가 명시적으로 정의되어 있지 않다면, 조인을 통해 새로운 Parititioner를 생성하게 된다. 이때 파티션의 개수는 spark.default.partitions로 설정된 값을 활용하거나, 두 RDD의 파티션 중 더 많은 파티션의 개수를 활용한다. 

***

## subtract나 subtractByKey 변환 연산자로 공통 값 제거

#### 1) subtract

첫번째 RDD에서 두번째 RDD 요소를 제거한 여집합 반환한다. Pari RDD뿐 아닌 모든 RDD에서 사용할 수 있는 함수이다. 

#### 2) subtractBykey

PairRDD에서만 활용 가능한 함수이다. 첫번째 RDD의 Key중 두번째 RDD에는 존재하지 않는 Key와 Value의 조합만을 반환한다.

        scala> val missingProds = products.subtractByKey(totalsByProd).values
        missingProds: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[66] at values at <console>:34

        scala> missingProds .foreach( p => println(p.mkString(",")))

        20,LEGO Elves,4589.79,4
        3,Cute baby doll, battery,1808.79,2
        43,Tomb Raider PC,2718.14,1
        63,Pajamas,8131.85,3


## cogroup 변환 연산자로 RDD조인

`cogroup`은 여러 RDD 값을 키로 그루핑하고, 각 RDD의 키별 값을 담은 iterable 객체 배열을 생성해 PairRDD의 value로 반환한다. 


cogroup은 최대 3개의 RDD를 조인할 수 있다. 단, 모든 RDD는 서로 동일한 타입의 Key값을 가지고 있어야 한다. 

> _cogroup[W1, W2](other1:RDD[(K,W1)], other2:RDD[(K,W2)]) : RDD(K, (Iterable[V], Iterable[W1], Iterable[W2]))_

    val prodTotCogroup = totalsByProd.cogroup(products)
    prodTotCogroup: org.apache.spark.rdd.RDD[(Int, (Iterable[Double], Iterable[Array[String]]))] = MapPartitionsRDD       

두 RDD중 한쪽에만 등장하는 키의 경우 다른쪽 RDD의 iterable은 비어있게 된다.

## intersection 변환 연산자 사용으로 교집합 구하기

intersection은 타입이 동일한 두 RDD에서 양쪽 모두에 포함된 공통요소, 즉 교집합을 RDD로 반환한다. 

    totalsByProd.map(_._1).intersection(products.map(_._1))


## cartesian 변환 연산자

두 RDD의 데카르트 곱을 계산한다. 즉, RDD[T]와 RDD[U]가 있다고 가정할 때, 두개의 RDD요소로 만들 수 있는 모든 조합의 {T,U}쌍의 튜플형태로 구성한다. 

    scala> val rdd1 = sc.parallelize(List(7,8,9))
    scala> val rdd2 = sc.parallelize(List(1,2,3))
    scala> rdd1.cartesian(rdd2).collect()
    res0: Array[(Int, Int)] = Array((7,1), (7,2), (7,3), (8,1), (8,2), (8,3), (9,1), (9,2), (9,3))

또한, 두 RDD 요소들을 서로 비교하는 데도 사용 가능하다. 

    scala> rdd1.cartesian(rdd2).filter(el => el._1 % el._2 ==0).collect()
    res1: Array[(Int, Int)] = Array((7,1), (8,1), (9,1), (8,2), (9,3))


보면 알겠지만, 이러한 연산은 커다란 메모리 용량을 필요로할 수 밖에 없다.  

## zip 연산자
두개의 RDD의 요소를 순서대로 짝을 지어 새로운 RDD를 반환한다.
두개의 RDD는 반드시 같은 개수의 파티션과 각 파티션이 서로 모두 동일한 개수의 요소를 포함하고 있어야 한다. 

    scala> val rdd1 = sc.parallelize(List(1,2,3))
    scala> val rdd2 = sc.parallelize(List("n4","n5","n6"))
    scala> rdd1.zip(rdd2).collect()
    res1: Array[(Int, String)] = Array((1,"n4"), (2,"n5"), (3,"n6"))

## zipPartitions 변환 연산자

첫 번째 인자의 두번째 요소가 true일 경우 현재의 파티션을 유지하며 false일 경우 새로운 파티션이 구성되어 셔플링이 발생한다.

두번째 인자는 두개의 RDD에서 추출된 iterator를 활용해 어떤 방식으로 결합을 할 것인지 결정할 수 있다.

zipAll은 두개의 컬렉션의 크기가 달라도 결합할 수 있다는 장점이 있다. 두번째 매개변수는 첫번째 컬렉션이, 세번째 매개변수는 두번째 컬렉션의 갯수가 다른 컬렉션보다 부족할 경우 대체값으로 활용할 수 있는 일종의 모조값이라고 할 수 있다.

    scala> val rdd1 = sc.parallelize(1 to 10, 10)
    scala> val rdd2 = sc.parallelize((1 to 8).map(x=>"n"+x), 10)
    scala> rdd1.zipPartitions(rdd2, true)((iter1, iter2) => {
            iter1.zipAll(iter2, -1, "empty")
            .map({case(x1, x2)=>x1+"-"+x2})
           }).collect()
    res1: Array[String] = Array(1-empty, 2-n1, 3-n2, 4-n3, 5-n4, 6-empty, 7-n5, 8-n6, 9-n7, 10-n8)

          